samplesize <- 16
hist.title <- "sample mean"
parameter.value <- mu
statistic.value <- function(x) mean(x)
mu <- 36.75
sigma <- 0.45
hist.title <- "sample mean"
parameter.value <- mu
statistic.value <- function(x) mean(x)
hist.title <- "sample median"
parameter.value <- mu
statistic.value <- function(x) median(x)
hist.title <- "sample third quartile"
parameter.value <- qnorm(0.75, mean=mu, sd=sigma)
statistic.value <- function(x) quantile(x, 0.75)
hist.title <- "sample standard deviation"
parameter.value <- sigma
statistic.value <- function(x) sd(x)
hist.title <- "sample IQR"
parameter.value <- qnorm(0.75, mean=mu, sd=sigma)-qnorm(0.25, mean=mu, sd=sigma)
statistic.value <- function(x) IQR(x)
#################################################
# empirical distribution based on 10000 samples
#
samplesize <- 5 # sample size n
all.samples <- c()
for (i in 1:10000){
x <- rnorm(samplesize, mean=mu, sd=sigma)
all.samples <- c(all.samples, statistic.value(x))
}
hist(all.samples, freq=FALSE, col="lightgray", main=hist.title)
abline(v=parameter.value, col="red", lty=2, lwd=3)
samplesize <- 16
x.bar <- c()
for (i in 1:10000) x.bar <- c(x.bar, mean(rnorm(samplesize, mu, sigma)))
hist(x.bar, freq=FALSE, xlim=c(mu-3*sigma, mu+3*sigma))
curve(dnorm(x, mean=mu, sd=sigma), add=TRUE, lwd=2, col="red")
curve(dnorm(x, mean=mu, sd=sigma/sqrt(samplesize)), add=TRUE, lwd=2, col="blue")
mu <- 36.75
sigma <- 0.45
mu.hat.1 <- c()
mu.hat.2 <- c()
Advertising <- read.csv("Advertising.csv")
attach(Advertising)
plot(TV, sales, pch=20)
Advertising <- read.csv("Advertising.csv")
attach(Advertising)
plot(TV, sales, pch=20)
# sample size
n <- length(sales)
Advertising <- read.csv("Advertising.csv")
Advertising <- read.csv("\Advertising.csv")
Advertising <- read.csv("/Advertising.csv")
Advertising <- read.csv("/Users/joanorellanarios/Library/CloudStorage/GoogleDrive-joanorellanarios@gmail.com/La meva unitat/Master/Second Semester/Statistical Learning Mod B/Advertising.csv")
attach(Advertising)
plot(TV, sales, pch=20)
# sample size
n <- length(sales)
n
plot((TV-mean(TV)), (sales-mean(sales)), pch=20)
abline(h=0, v=0, lwd=2)
par(mfrow=c(1, 2))
plot(TV, sales, pch=20)
abline(h=mean(sales), v=mean(TV), lwd=2)
plot((TV-mean(TV)), (sales-mean(sales)), col=3+sign((TV-mean(TV))*(sales-mean(sales))), pch=20)
abline(h=0, v=0, lwd=2)
par(mfrow=c(1, 1))
cov.st <- sum((sales-mean(sales))*(TV-mean(TV)))/(n-1)
cov.st
cov(sales, TV)
cor.st <- cov.st/(sd(sales)*sd(TV))
cor.st
cor(sales, TV)
library(MASS)
data(mcycle)
attach(mcycle)
plot(times, accel, pch=20)
plot(times-mean(times), accel-mean(accel), pch=20)
abline(h=0, v=0, lwd=2)
cor(mcycle$times, mcycle$accel)
cov(Advertising)
cov(Advertising[,-1])
X <- Advertising[, -1]
is.matrix(X)
is.data.frame(X)
X <- as.matrix(X)
mean.vec <- apply(X, 2, mean)
mean.vec
uv <- rep(1, n)
Xc <- X- uv%*%t(mean.vec)
# check that variables are centered
round(apply(Xc, 2, sum), 5)
cov.mat <- t(Xc)%*%Xc/(n-1)
cov.mat
cov(X)
D <- diag(cov.mat)
D
D <- diag(D)
D
cor.mat <- solve(sqrt(D))%*%cov.mat%*%solve(sqrt(D))
cor.mat
cov2cor(cov.mat)
cor(X)
pairs(X)
pairs(X, diag.panel=panel.hist)
pairs(X, diag.panel=panel.hist, upper.panel=panel.cor)
pairs(X, diag.panel=panel.hist, upper.panel=panel.cor, lower.panel=panel.smooth)
## panel.hist function
## put histograms on the diagonal
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
## panel.cor function
## put (absolute) correlations on the upper panels,
## with size proportional to the correlations.
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits = digits)[1]
txt <- paste0(prefix, txt)
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
library(ellipse)
plotcorr(cor(X))
x <- TV
y <- sales
plot(x, y, pch=20)
beta1.hat <- cov(x, y)/var(x)
beta0.hat <- mean(y)- beta1.hat*mean(x)
beta0.hat
beta1.hat
abline(beta0.hat, beta1.hat, col="blue", lwd=2)
y.hat <- beta0.hat+beta1.hat*x
points(x, y.hat, col="red", pch=20)
e <- y -y.hat
sum(e)
RSS <- sum(e^2)
RSS
RSE <- sqrt(RSS/(200-2))
RSE
reg.out <- lm(y~x)
summary(reg.out)
residuals(reg.out)
coefficients(reg.out)
confint(reg.out)
confint(reg.out, level=0.8)
e <- residuals(reg.out)
y.hat <- fitted.values(reg.out)
sum(e)
sum(e*x)
sum(e*y.hat)
TSS <- sum((y-mean(y))^2)
RSS <- sum((y-y.hat)^2)
R2 <- (TSS-RSS)/TSS
R2
reg.out.tv <-lm(sales~TV)
plot(TV, sales, pch=16)
abline(reg.out.tv)
summary(reg.out.tv)
beta.hat.tv <- coefficients(reg.out.tv)
y.hat.tv.150 <- beta.hat.tv[1]+beta.hat.tv[2]*150
y.hat.tv.150
points(150, y.hat.tv.150, pch="X", col="red")
reg.out.radio <-lm(sales~radio)
plot(radio, sales, pch=16)
abline(reg.out.radio)
summary(reg.out.radio)
beta.hat.radio <- coefficients(reg.out.radio)
y.hat.radio.25 <- beta.hat.radio[1]+beta.hat.radio[2]*25
y.hat.radio.25
points(25, y.hat.radio.25, pch="X", col="red")
reg.out.np <-lm(sales~newspaper)
plot(newspaper, sales, pch=16)
abline(reg.out.np)
summary(reg.out.np)
beta.hat.np <- coefficients(reg.out.np)
y.hat.np.60 <- beta.hat.np[1]+beta.hat.np[2]*60
y.hat.np.60
points(60, y.hat.np.60, pch="X", col="red")
cor(Advertising[, -c(1, 5)])
X <- cbind(1, Advertising[, 2:4])
X <- as.matrix(X)
X[1:5,]
y <- sales
n <- 200
p <- 3
t(X)%*%X
beta.hat <- solve(t(X)%*%X)%*%t(X)%*%y
beta.hat
y.hat <- X%*%beta.hat
e <- y - y.hat
round(sum(e), 3)
round(t(e)%*%X, 3)
round(t(e)%*%y.hat, 3)
RSE <- sqrt(t(e)%*%e/(n-p-1))
RSE
RSE <- sqrt(sum(e^2)/(n-p-1))
RSE
var.beta.hat <- RSE^2*solve(t(X)%*%X)
round(var.beta.hat, 7)
se.beta.hat <- sqrt(diag(var.beta.hat))
se.beta.hat
reg.out <- lm(sales~1+TV+radio+newspaper)
summary(reg.out)
reg.out <- lm(sales~TV+radio+newspaper)
summary(reg.out)
reg.out <- lm(sales~-1+TV+radio+newspaper)
summary(reg.out)
t.obs <- beta.hat/se.beta.hat
t.obs
p.values <- 2*pt(-abs(t.obs), n-p-1)
round(p.values, 4)
t_0.975 <- qt(0.975, n-p-1)
lower <- beta.hat -t_0.975*se.beta.hat
upper <- beta.hat +t_0.975*se.beta.hat
cbind(lower, upper)
confint(reg.out)
full.mod <- lm(sales~TV)
summary(full.mod)
beta1.hat <-coefficients(full.mod)[2]
beta1.hat
e <- residuals(full.mod)
RSS <- sum(e^2)
s2 <- RSS/(n-2)
RSE <- sqrt(s2)
RSE
se.hat <- sqrt(s2/sum((TV-mean(TV))^2))
se.hat
t.obs <- beta1.hat/se.hat
t.obs
p.value <- 2*(pt(-abs(t.obs), n-2))
p.value
F.obs <- t.obs^2
F.obs
1 - pf(F.obs, 1, n-2)
red.mod <- lm(sales~+1)
e0<- residuals(red.mod)
RSS0 <- sum(e0^2)
RSS0
sum((sales-mean(sales))^2)
F.obs <- (RSS0-RSS)/(RSS/(n-2))
F.obs
summary(full.mod)
reg.out1 <- lm(sales~TV+radio+newspaper)
reg.out0 <- lm(sales~+1)
RSS0 <- sum(residuals(reg.out0)^2)
RSS1 <- sum(residuals(reg.out1)^2)
F.obs <- ((RSS0-RSS1)/3)/(RSS1/(200-3-1))
F.obs
p.value <- 1 - pf(F.obs, 3, 196)
p.value
anova(reg.out0, reg.out1)
full.mod <- lm(sales~TV+radio+newspaper)
red.mod <-  lm(sales~TV)
anova(red.mod, full.mod)
out <- lm(sales~TV)
summary(out)$r.squared
out <- lm(sales~TV+radio)
summary(out)$r.squared
out <- lm(sales~TV+radio+newspaper)
summary(out)$r.squared
# package from the book "Introduction to Statistical Learning" 2nd edition
library(ISLR2)
data("Auto")
attach(Auto)
help(Auto)
names(Auto)
full.mod <- lm(mpg~cylinders+displacement+horsepower+weight+acceleration+year+origin+name)
summary(full.mod)
full.mod <- lm(mpg~., data=Auto)
summary(full.mod)
# remove the covariate "name"
full.mod <- lm(mpg~.-name, data=Auto)
summary(full.mod)
full.mod <- lm(mpg~.-name-origin, data=Auto)
summary(full.mod)
# backward stepwise procedure
red.mod1 <- update(full.mod, ~.-horsepower)
summary(red.mod1)
red.mod2 <- update(red.mod1, ~.-cylinders)
summary(red.mod2)
red.mod3 <- update(red.mod2, ~.-displacement)
summary(red.mod3)
red.mod4 <- update(red.mod3, ~.-acceleration)
summary(red.mod4)
anova(red.mod4, full.mod)
round(cor(Auto[,-c(1, 8, 9)]), 2)
pairs(Auto[,-c(1, 8, 9)])
red.mod <- update(full.mod, ~.-weight)
summary(red.mod)
attach(Advertising)
plot(TV, sales, pch=20)
# sample size
n <- length(sales)
n
plot(TV, sales, pch=20)
mod.out <- lm(sales~TV)
summary(mod.out)
abline(mod.out, lwd=2)
coefficients(mod.out)
7.03259355+0.04753664*170
points(170, 15.114, pch="X", col="red")
new.x <- data.frame(TV=170)
predict(mod.out, newdata=new.x)
predict(mod.out, newdata=new.x, interval ="confidence")
predict(mod.out, newdata=new.x, interval ="prediction")
range(TV)
xp <- seq(1, 295, length=100)
help(lm)
help("summary")
plot(TV, sales, pch=20)
mod.out <- lm(sales~TV)
summary(mod.out)
abline(mod.out, lwd=2)
coefficients(mod.out)
7.03259355+0.04753664*170
points(170, 15.114, pch="X", col="red")
new.x <- data.frame(TV=170)
predict(mod.out, newdata=new.x)
predict(mod.out, newdata=new.x, interval ="confidence")
predict(mod.out, newdata=new.x, interval ="prediction")
range(TV)
xp <- seq(1, 295, length=100)
new.x <- data.frame(TV=xp)
new.conf <- predict(mod.out, newdata=new.x, interval = "confidence")
lines(xp, new.conf[,2], lty=2, col="red", lwd=2)
lines(xp, new.conf[,3], lty=2, col="red", lwd=2)
new.pred <- predict(mod.out, newdata=new.x, interval = "prediction")
lines(xp, new.pred[,2], lty=2, col="blue", lwd=2)
lines(xp, new.pred[,3], lty=2, col="blue", lwd=2)
plot(TV, sales, pch=20)
mod.out <- lm(sales~TV)
summary(mod.out)
# residual plot with covariate "TV" on the x-axis
#
par(mfrow=c(1,2))
plot(TV, sales)
abline(mod.out, col="blue", lwd=2)
plot(TV, residuals(mod.out), col="gray40", xlab="TV", ylab="residuals")
lines(loess.smooth(TV, residuals(mod.out)), col="blue", lwd=2)
abline(h=0, lty=2)
par(mfrow=c(1,1))
# residual plot with fitted.values on the x-axis
#
par(mfrow=c(1,2))
plot(TV, sales)
abline(mod.out, col="blue", lwd=2)
plot(fitted(mod.out), residuals(mod.out), col="gray40", xlab="fitted values", ylab="residuals")
lines(loess.smooth(fitted(mod.out), residuals(mod.out)), col="blue", lwd=2)
abline(h=0, lty=2)
par(mfrow=c(1,1))
plot(mod.out)
data(Auto)
attach(Auto)
mod.out <- lm(mpg~horsepower)
summary(mod.out)
par(mfrow=c(1,2))
plot(horsepower, mpg)
abline(mod.out, col="blue", lwd=2)
plot(fitted(mod.out), residuals(mod.out), col="gray40", xlab="fitted values", ylab="residuals")
lines(loess.smooth(fitted(mod.out), residuals(mod.out)), col="blue", lwd=2)
abline(h=0, lty=2)
par(mfrow=c(1,1))
plot(horsepower, mpg, pch=16)
abline(mod.out, lwd=2)
xp <- c(60, 130, 200)
new.x <- data.frame(horsepower=xp)
new.y <- predict(mod.out, newdata=new.x)
points(xp, new.y, pch=17, col="red", cex=1.4)
plot(fitted.values(mod.out), residuals(mod.out), pch=20)
abline(h=0)
mod.out2 <- lm(mpg  ~ horsepower + I(horsepower^2))
summary(mod.out2)
plot(horsepower, mpg, pch=20)
range(horsepower)
xp <- seq(46, 230, length=100)
new.x <- data.frame(horsepower=xp)
yp <- predict(mod.out2, newdata=new.x)
lines(xp, yp, lwd=2, col="red")
help(fitted.values)
library(MASS)
data(mcycle)
attach(mcycle)
plot(times, accel, xlab="Time", ylab="Acc.", pch=20)
times.st <- times - mean(times)
pol15 <- lm(accel~times.st+I(times.st^2)+I(times.st^3)
+I(times.st^4)+I(times.st^5)+ I(times.st^6)
+I(times.st^7)+I(times.st^8)+I(times.st^9)
+I(times.st^10)+I(times.st^11)+I(times.st^12)
+I(times.st^13)+I(times.st^14)+I(times.st^15))
anova(pol15)
help(anova)
pol12 <- lm(accel~times.st+I(times.st^2)+I(times.st^3)
+I(times.st^4)+I(times.st^5)+I(times.st^6)
+I(times.st^7)+I(times.st^8)+I(times.st^9)
+I(times.st^10)+I(times.st^11)+I(times.st^12))
summary(pol12)
par(mfrow=c(2,2))
plot(pol12)
par(mfrow=c(1,1))
plot(times, accel)
lines(times, pol12$fitted)
pred <- predict(pol12, data.frame(times.st=20:30-mean(times)),
interval="prediction", level=0.95)
pred
points(20:30, pred[,1], col="red")
library(faraway)
data(orings)
orings[1,2] <- 1
attach(orings)
linear.out <- lm(damage~temp)
summary(linear.out)
plot(temp, damage, pch=20, xlim=c(45, 85), ylim=c(-.25, 1.25))
abline(linear.out)
new.temp <- data.frame(temp=c(31, 82))
predict(linear.out, newdata=new.temp)
logit.out <- glm(damage ~ temp, family = binomial)
logit.out
summary(logit.out)
plot(temp, damage, pch=20, xlim=c(45, 85), ylim=c(-.25, 1.25))
# function to compute the inverse of the logit
inv.logit <- function(beta0, beta1, x) {
y <- exp(beta0+beta1*x)
return(y/(1+y))
}
x <- seq(45, 85, length=100)
beta.hat <- coefficients(logit.out)
beta0.hat <- beta.hat[1]
beta1.hat <- beta.hat[2]
y <- inv.logit(beta0.hat, beta1.hat, x)
lines(x, y, col="blue", lwd=1.5)
# comparison with the linear model
abline(linear.out)
new.temp <- data.frame(temp=31)
# predict the expected value (probability)
prob.hat <-predict(logit.out, newdata=new.temp, type="response")
prob.hat
# compute the logit
log(prob.hat/(1-prob.hat))
json_data_frame <- as.data.frame(grammy)
attach(sp_y)
hist(Views)
setwd("/Users/joanorellanarios/Library/CloudStorage/GoogleDrive-joanorellanarios@gmail.com/La meva unitat/Master/Second Semester/Statistical Learning Mod B/SL_Project")
setwd("/Users/joanorellanarios/Library/CloudStorage/GoogleDrive-joanorellanarios@gmail.com/La meva unitat/Master/Second Semester/Statistical Learning Mod B/SL_Project")
setwd("/Users/joanorellanarios/Library/CloudStorage/GoogleDrive-joanorellanarios@gmail.com/La meva unitat/Master/Second Semester/Statistical Learning Mod B/SL_Project")
setwd("/Users/joanorellanarios/Library/CloudStorage/GoogleDrive-joanorellanarios@gmail.com/La meva unitat/Master/Second Semester/Statistical Learning Mod B/SL_Project")
install.packages("rjson")
install.packages("rjson")
install.packages("rjson")
library("rjson")
sp_y <- read.csv("Spotify_Youtube.csv", sep=',')
grammy <- fromJSON(file = "grammy.json", flatten=TRUE)
json_data_frame <- as.data.frame(grammy)
attach(sp_y)
hist(Views)
summary(sp_y)
sp_y <- read.csv("Spotify_Youtube.csv", sep=',')
grammy <- read.csv("grammySongs.csv", sep=',')
json_data_frame <- as.data.frame(grammy)
View(grammy)
View(grammy)
sp_y <- read.csv("Spotify_Youtube.csv", sep=',')
View(sp_y)
View(sp_y)
sp_y <- read.csv("Spotify_Youtube.csv", sep=',')
sp_y$unique <- paste(sp_y$Artist, "_", sp_y$Track)
grammy <- read.csv("grammySongs.csv", sep=',')
grammy$unique <- paste(grammy$Artist, "_", grammy$Name)
df <- inner_join(sp_y, grammy, by = "unique")
library(dplyr)
df <- inner_join(sp_y, grammy, by = "unique")
View(df)
View(df)
df <- left_join(sp_y, grammy, by = "unique")
View(faithful)
View(df)
summary(df)
colnames(df)
View(df)
df = df[c('X.x', 'Artist.x', 'Track', 'Album', 'Album_type', 'Danceability', "Energy", "Key", "Loudness", "Speechiness", "Acousticness", "Instrumentalness", "Liveness", "Valence", "Tempo", "Duration_ms", "Views", "Likes", "Comments", "GrammyAward", "GrammyYear", "Genre")]
df$winner <- ifelse(is.na(df$GrammyAward),TRUE, FALSE)
df$winner <- ifelse(!is.na(df$GrammyAward),TRUE, FALSE)
source("~/Library/CloudStorage/GoogleDrive-joanorellanarios@gmail.com/La meva unitat/Master/Second Semester/Statistical Learning Mod B/SL_Project/test.R")
plot(cars)
plot(cars)
head(df, 6 )
cor(df, use = "complete.obs")
cor(df)
audio_f <- df[c('Danceability', "Energy", "Key", "Loudness", "Speechiness", "Acousticness", "Instrumentalness", "Liveness", "Valence", "Tempo", "Duration_ms")]
"Speechiness""Speechiness""Acousticness""Acousticness"
head(audio_f, 6)
audio_f <- df[c('Danceability', "Energy", "Key", "Loudness", "Speechiness", "Acousticness", "Instrumentalness", "Liveness", "Valence", "Tempo", "Duration_ms", "Winner")]
audio_f <- df[c('Danceability', "Energy", "Key", "Loudness", "Speechiness", "Acousticness", "Instrumentalness", "Liveness", "Valence", "Tempo", "Duration_ms", "Winner")]
audio_f <- df[c('Danceability', "Energy", "Key", "Loudness", "Speechiness", "Acousticness", "Instrumentalness", "Liveness", "Valence", "Tempo", "Duration_ms", "winner")]
head(audio_f, 6)
cor(audio_f)
audio_f <- df[c('Danceability', "Energy", "Key", "Loudness", "Speechiness", "Acousticness", "Instrumentalness", "Liveness", "Valence", "Tempo", "Duration_ms")]
head(audio_f, 6)
cor(audio_f)
audio_f <- df[c('Danceability', "Energy", "Key", "Loudness", "Speechiness", "Acousticness", "Instrumentalness", "Liveness", "Valence", "Tempo")]
head(audio_f, 6)
cor(audio_f)
source("~/Library/CloudStorage/GoogleDrive-joanorellanarios@gmail.com/La meva unitat/Master/Second Semester/Statistical Learning Mod B/SL_Project/test.R")
