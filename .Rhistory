beta.hat +c(-1,1)*qnorm(0.975)*se.beta
ls
is()
ls()
x = c(1, 2 NA, 4)
c <- c(1, 2, NA, 4)
x <- c(1, 2, NA, 4)
y <- c(1, NA, 3, 4)
x + y
Advertising <- read.csv("Advertising.csv")
Advertising <- read.csv("Advertising.csv")
Advertising <- read.csv("Advertising.csv")
library(ISLR2)
data("Default")
attach(Default)
l <- default=="Yes"
plot(balance, income, col=l+1, pch=l*15+1)
mod.out <- glm(default ~ income + balance, family = binomial)
logistic.prob <- predict(mod.out, type="response")
logistic.pred <- rep("No", 10000)
logistic.pred[logistic.prob>0.5] <- "Yes"
default[200:215]
logistic.pred[200:215]
default[200:215]==logistic.pred[200:215]
summary(mod.out)
beta <- coefficients(mod.out)
intercept <- -beta[1]/beta[2]
slope <- -beta[3]/beta[2]
plot(balance, income, col=l+1, pch=l*15+1)
abline(intercept, slope, lwd=2, col="blue")
table(logistic.pred, default)
# overall (training) error rate
(225+38)/10000
trivial.pred <- rep("No", 10000)
table(trivial.pred, default)
# overall (training) error rate for the trivial classifier
333/10000
# (training) error rate for defaulting-customers
table(logistic.pred, default)
225/(225+108)
logistic.pred <- rep("No", 10000)
logistic.pred[logistic.prob>0.2] <- "Yes"
table(logistic.pred, default)
# overall (training) error rate
(133+271)/10000
# (training) error rate among individuals who defaulted
133/(133+200)
logistic.pred <- rep("No", 10000)
logistic.pred[logistic.prob>0.5] <- "Yes"
CM <- table(logistic.pred, default)
# rearrange rows and columns to match
# the confusion matrix on the slides
CM <- CM[2:1, 2:1]
logistic.pred <- rep("No", 10000)
logistic.pred[logistic.prob>0.5] <- "Yes"
CM <- table(logistic.pred, default)
CM
# rearrange rows and columns to match
# the confusion matrix on the slides
CM <- CM[2:1, 2:1]
CM
# add margins to the confusion matrix
# obtain the totals
CM <- addmargins(CM, margin = c(1, 2))
CM
# false positive rate = FP / N (false pos over total negative)
fpr <- 38/9667
fpr
fpr <- CM["Yes", "No"]/CM["Sum", "No"]
fpr
specif <- 1 - fpr
specif
tpr <- 108/333
tpr
tpr <- CM["Yes", "Yes"]/CM["Sum", "Yes"]
tpr
CM
library(pROC)
# default are true predictions, then prob are your predictions
roc.out <- roc(default, logistic.prob)
roc.out <- roc(default, logistic.prob, levels=c("No", "Yes"))
# argument "legacy.axes" is a logical indicating if the specificity axis
# (x axis) must be plotted as as decreasing “specificity” (FALSE, the default)
# or increasing “1 - specificity” (TRUE)
plot(roc.out)
# ROC curve traditionally represented with respect to specificity
#   and Sensitivity
#   Specificity is what you want large, so the x-axis is backwards
#      (decreases from 1)
plot(roc.out, legacy.axes=TRUE)
plot(roc.out,  print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
# and you can compute AUC
auc(roc.out)
plot(roc.out,  print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
# specificity and sensitivity for a given threshold
coords(roc.out, x=0.2)
# threshold that maximizes the sum of sensitivity and specificity
coords(roc.out, x="best")
library(ISLR2)
names(Smarket)
dim(Smarket)
summary(Smarket)
# summary prints the variables
pairs(Smarket)
cor(Smarket)
cor(Smarket)
round(cor(Smarket[,-9]), 3)
attach(Smarket)
plot(Volume, xlab="time")
glm.fits <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial)
summary(glm.fits)
# alternative syntax using the "dot"
glm.fits <- glm(Direction~.-Today-Year, data=Smarket, family=binomial)
summary(glm.fits)
# obtain fitted probabilities
glm.probs <- predict(glm.fits, type="response")
glm.probs[1:10]
# check the coding of Direction (to properly interpret probabilities)
contrasts(Direction)
glm.pred <- rep("Down",1250)
glm.pred[glm.probs>.5] <- "Up"
table(glm.pred,Direction)
# overall (training) error rate
(141+457)/1250
# 0.4784; or 47%
#   We know that random guessing (toss a coin to choose investments), error rate is 50%
#      This is slightly smaller than 50%, but this is a training error rate
#      This error rate is underestimated, true error is most likely large (probably 50%)
Direction
# proportions of "Up" and "Down"
table(Direction)/length(Direction)
library(pROC)
roc.out <- roc(Direction, glm.probs, levels=c("Down", "Up"))
plot(roc.out, print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
# reduced set of predictors
####################################
# Let's try tor educe number of predictiors: Lag1 and Lag2
glm.fits <- glm(Direction~Lag1+Lag2,data=Smarket,family=binomial)
glm.probs <- predict(glm.fits,type="response")
glm.pred <- rep("Down",1250)
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction)
# overall error rate
(102+488)/1250
table(Direction)/length(Direction)
train <- (Year<2005)
# creates a logical vector, T for data before 2005 and F for later
# Train on data from years less than 2005
Smarket.2005 <- Smarket[!train,]
# When we take S market and !train logical vector, we obtain the data for 2005
#   This is out validation set
dim(Smarket.2005)
# Could also
Direction.2005 <- Direction[!train]
# fit for same variables on Smarket on the subset train
#   Only works with the data where Train vector index is True
glm.fits <- glm(Direction~.-Today-Year, family=binomial, data=Smarket, subset=train)
# prediction on hold-out set
glm.probs <- predict(glm.fits,Smarket.2005,type="response")
glm.pred <- rep("Down",252)
glm.pred[glm.probs>.5] <- "Up"
table(glm.pred,Direction.2005)
(97+34)/252
table(Direction.2005)/length(Direction.2005)
x <- 1:4
x
x[2]
x[0]
x[0]
### Data Preprocessing
# Set the working directory to this file's folder
library("rstudioapi")
setwd(dirname(getActiveDocumentContext()$path))
load("final_df_n_str.RData")
Sys.setenv(LANG = "en")
#install.packages("correlation")
#install.packages("confintr")
#install.packages("ROSE")
#install.packages("caret")
#install.packages("glmnet")
library(pROC)
library(MASS)
library(ROSE)
library(confintr)
library(ggplot2)
library(correlation)
library(corrplot)
library(class)
library(caret)
library(glmnet)
# Selecting the relevant variables
data = final_df_n_str
data = data[,c("track_name", "artist_name", "IsWinner", "Year","year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
# Merge the two year variable
data$Year[data$Year == "Undefined"] <- data$year[data$Year == "Undefined"]
data = data[,c("track_name","artist_name", "IsWinner", "Year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
# Eliminating duplicates
data$track_name == "Closing Time"
data$track_name == "Smells Like Teen Spirit"
data$track_name == "Don't Wanna Fight"
data[914, ]
data[789,]
data[669,]
data = data[-c(669, 789, 914),]
sum(data$Year < 1992)
nrow(data)
data = data[!data$Year < 1992,]
# Creating row names
names = paste0(data$track_name, " - ", data$artist_name)
# Eliminating unusable variables
data = data[,c("IsWinner", "Year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
data = cbind(names = names, data)
# Casting variables
data$IsWinner[data$IsWinner == "Winner"] = 1
data$IsWinner[data$IsWinner == "Nominee"] = 1
data$IsWinner[data$IsWinner == "Nothing"] = 0
data$IsWinner = as.integer(data$IsWinner)
data$Year = as.integer(data$Year)
data$mode = as.factor(data$mode)
data$key = as.factor(data$key)
data$time_signature = as.factor(data$time_signature)
summary(data)
length(data$IsWinner[data$IsWinner == 0]) / (length(data$IsWinner[data$IsWinner == 0]) + length(data$IsWinner[data$IsWinner == 1]))
length(data$IsWinner[data$IsWinner == 1]) / (length(data$IsWinner[data$IsWinner == 0]) + length(data$IsWinner[data$IsWinner == 1]))
# Set the working directory to this file's folder
library("rstudioapi")
setwd(dirname(getActiveDocumentContext()$path))
load("final_df_n_str.RData")
Sys.setenv(LANG = "en")
library(pROC)
library(MASS)
library(ROSE)
library(confintr)
library(ggplot2)
library(correlation)
library(corrplot)
library(class)
library(caret)
library(glmnet)
data = final_df_n_str
data = data[,c("track_name", "artist_name", "IsWinner", "Year","year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
data$Year[data$Year == "Undefined"] <- data$year[data$Year == "Undefined"]
data = data[,c("track_name","artist_name", "IsWinner", "Year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
data$track_name == "Closing Time"
data$track_name == "Smells Like Teen Spirit"
data$track_name == "Don't Wanna Fight"
data[914, ]
data[789,]
data[669,]
data = data[-c(669, 789, 914),]
sum(data$Year < 1992)
nrow(data)
data = data[!data$Year < 1992,]
names = paste0(data$track_name, " - ", data$artist_name)
data = data[,c("IsWinner", "Year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
data = cbind(names = names, data)
data$IsWinner[data$IsWinner == "Winner"] = 1
data$IsWinner[data$IsWinner == "Nominee"] = 1
data$IsWinner[data$IsWinner == "Nothing"] = 0
data$IsWinner = as.integer(data$IsWinner)
data$Year = as.integer(data$Year)
data$mode = as.factor(data$mode)
data$key = as.factor(data$key)
data$time_signature = as.factor(data$time_signature)
summary(data)
length(data$IsWinner[data$IsWinner == 0]) / (length(data$IsWinner[data$IsWinner == 0]) + length(data$IsWinner[data$IsWinner == 1]))
length(data$IsWinner[data$IsWinner == 1]) / (length(data$IsWinner[data$IsWinner == 0]) + length(data$IsWinner[data$IsWinner == 1]))
training_size = floor(0.8 * nrow(data))
set.seed(42)
train_ind = sample(seq_len(nrow(data)), size = training_size)
training_set = data[train_ind,]
test_set = data[-train_ind,]
summary(training_set)
length(training_set$IsWinner[data$IsWinner == 0]) / (length(training_set$IsWinner[data$IsWinner == 0]) + length(training_set$IsWinner[data$IsWinner == 1]))
length(training_set$IsWinner[data$IsWinner == 1]) / (length(training_set$IsWinner[data$IsWinner == 0]) + length(training_set$IsWinner[data$IsWinner == 1]))
length(test_set$IsWinner[data$IsWinner == 0]) / (length(test_set$IsWinner[data$IsWinner == 0]) + length(test_set$IsWinner[data$IsWinner == 1]))
length(test_set$IsWinner[data$IsWinner == 1]) / (length(test_set$IsWinner[data$IsWinner == 0]) + length(test_set$IsWinner[data$IsWinner == 1]))
attach(training_set)
# Correlations between continuous variables
cor_matrix = cor(training_set[,c(-1, -2, -10, -13, -15)])
corrplot(cor_matrix)
# Send pairs() to PDF to resize and visualize better
pdf(file = "yourPlot.pdf", width = 10, height = 8)
pairs(training_set[,c(-1, -2, -10, -13, -15)], lower.panel = panel.smooth)
dev.off()  # important!
# Association measure for categorical variables (Cramer's V is a normalized
# version of the chi-square statistics)
cramersv(matrix(c(as.numeric(key), as.numeric(mode)), ncol = 2))
cramersv(matrix(c(as.numeric(key), as.numeric(time_signature)), ncol = 2))
cramersv(matrix(c(as.numeric(mode), as.numeric(time_signature)), ncol = 2))
fol_key.aov <- aov(followers ~ key)
summary(fol_key.aov) # SIGNIFICANT
aco_key.aov <- aov(acousticness ~ key)
summary(aco_key.aov)
dan_key.aov <- aov(danceability ~ key)
summary(dan_key.aov) # SIGNIFICANT
dur_key.aov <- aov(duration_ms ~ key)
summary(dur_key.aov)
ene_key.aov <- aov(energy ~ key)
summary(ene_key.aov) # SIGNIFICANT
ins_key.aov <- aov(instrumentalness ~ key)
summary(ins_key.aov)
liv_key.aov <- aov(liveness ~ key)
summary(liv_key.aov)
loud_key.aov <- aov(loudness ~ key)
summary(loud_key.aov)
tem_key.aov <- aov(tempo ~ key)
### Data Preprocessing
# Set the working directory to this file's folder
library("rstudioapi")
setwd(dirname(getActiveDocumentContext()$path))
load("final_df_n_str.RData")
Sys.setenv(LANG = "en")
#install.packages("correlation")
#install.packages("confintr")
#install.packages("ROSE")
#install.packages("caret")
#install.packages("glmnet")
library(pROC)
library(MASS)
library(ROSE)
library(confintr)
library(ggplot2)
library(correlation)
library(corrplot)
library(class)
library(caret)
library(glmnet)
# Selecting the relevant variables
data = final_df_n_str
data = data[,c("track_name", "artist_name", "IsWinner", "Year","year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
# Merge the two year variable
data$Year[data$Year == "Undefined"] <- data$year[data$Year == "Undefined"]
data = data[,c("track_name","artist_name", "IsWinner", "Year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
# Eliminating duplicates
data$track_name == "Closing Time"
data$track_name == "Smells Like Teen Spirit"
data$track_name == "Don't Wanna Fight"
data[914, ]
data[789,]
data[669,]
data = data[-c(669, 789, 914),]
sum(data$Year < 1992)
nrow(data)
data = data[!data$Year < 1992,]
# Creating row names
names = paste0(data$track_name, " - ", data$artist_name)
# Eliminating unusable variables
data = data[,c("IsWinner", "Year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
data = cbind(names = names, data)
# Casting variables
data$IsWinner[data$IsWinner == "Winner"] = 1
data$IsWinner[data$IsWinner == "Nominee"] = 1
data$IsWinner[data$IsWinner == "Nothing"] = 0
data$IsWinner = as.integer(data$IsWinner)
data$Year = as.integer(data$Year)
data$mode = as.factor(data$mode)
data$key = as.factor(data$key)
data$time_signature = as.factor(data$time_signature)
summary(data)
# Checking balance between classes
length(data$IsWinner[data$IsWinner == 0]) / (length(data$IsWinner[data$IsWinner == 0]) + length(data$IsWinner[data$IsWinner == 1]))
length(data$IsWinner[data$IsWinner == 1]) / (length(data$IsWinner[data$IsWinner == 0]) + length(data$IsWinner[data$IsWinner == 1]))
# Splitting training and test set
training_size = floor(0.8 * nrow(data))
set.seed(42)
train_ind = sample(seq_len(nrow(data)), size = training_size)
training_set = data[train_ind,]
test_set = data[-train_ind,]
summary(training_set)
# Checking if the ratio is preserved
length(training_set$IsWinner[data$IsWinner == 0]) / (length(training_set$IsWinner[data$IsWinner == 0]) + length(training_set$IsWinner[data$IsWinner == 1]))
length(training_set$IsWinner[data$IsWinner == 1]) / (length(training_set$IsWinner[data$IsWinner == 0]) + length(training_set$IsWinner[data$IsWinner == 1]))
length(test_set$IsWinner[data$IsWinner == 0]) / (length(test_set$IsWinner[data$IsWinner == 0]) + length(test_set$IsWinner[data$IsWinner == 1]))
length(test_set$IsWinner[data$IsWinner == 1]) / (length(test_set$IsWinner[data$IsWinner == 0]) + length(test_set$IsWinner[data$IsWinner == 1]))
###############################################################################
# Exploratory Data Analysis
# Relationship between independent variables
attach(training_set)
# Correlations between continuous variables
cor_matrix = cor(training_set[,c(-1, -2, -10, -13, -15)])
# corrplot(cor_matrix, method='number')
png(file="corplot_indep_1.png",
width=600, height=350)
corrplot(cor_matrix, method='number')
dev.off()
# corrplot(cor_matrix, method='number')
png(file="corplot_indep_1.png",
width=800, height=350)
corrplot(cor_matrix, method='number')
dev.off()
# Correlations between continuous variables
cor_matrix = cor(training_set[,c(-1, -2, -10, -13, -15)])
# corrplot(cor_matrix, method='number')
dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=600, height=350)
corrplot(cor_matrix, method='number')
dev.off()
# corrplot(cor_matrix, method='number')
png(file="corplot_indep_1.png",
width=10, height=5, unit = in)
corrplot(cor_matrix, method='number')
dev.off()
# corrplot(cor_matrix, method='number')
png(file="corplot_indep_1.png",
width=10, height=5, unit = 'in')
corrplot(cor_matrix, method='number')
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=10, height=5, unit = in)
corrplot(cor_matrix, method='number', number.cex = 0.8)
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=650, height=300)
corrplot(cor_matrix, method='number', number.cex = 0.8)
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=650, height=300)
corrplot(cor_matrix, method='number', number.cex = 1.2)
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=650, height=300)
corrplot(cor_matrix, method='number', pointsize = 15)
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1500, height=1200)
corrplot(cor_matrix, method='number', pointsize = 15)
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000)
corrplot(cor_matrix, method='number', pointsize = 15)
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000, pointsize = 15)
corrplot(cor_matrix, method='number')
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000, pointsize = 30)
corrplot(cor_matrix, method='number')
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000, pointsize = 30)
corrplot.mixed(cor_matrix, method='number')
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000, pointsize = 30)
corrplot.mixed(cor_matrix)
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000, pointsize = 30)
corrplot.mixed(cor_matrix)
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000, pointsize = 30)
corrplot.mixed(cor_matrix, tl.pos='lt')
dev.off()
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000, pointsize = 26)
corrplot.mixed(cor_matrix, tl.pos='lt')
dev.off()
# Send pairs() to PDF to resize and visualize better
png(file = "corplot_indep_2.png", width = 1200, height = 1000, pointsize=15)
pairs(training_set[,c(-1, -2, -10, -13, -15)], lower.panel = panel.smooth)
dev.off()  # important!
# Send pairs() to PDF to resize and visualize better
png(file = "corplot_indep_2.png", width = 1200, height = 1000, pointsize=20)
pairs(training_set[,c(-1, -2, -10, -13, -15)], lower.panel = panel.smooth)
dev.off()  # important!
