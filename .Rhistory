plot(roc.out)
# ROC curve traditionally represented with respect to specificity
#   and Sensitivity
#   Specificity is what you want large, so the x-axis is backwards
#      (decreases from 1)
plot(roc.out, legacy.axes=TRUE)
plot(roc.out,  print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
# and you can compute AUC
auc(roc.out)
plot(roc.out,  print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
# specificity and sensitivity for a given threshold
coords(roc.out, x=0.2)
# threshold that maximizes the sum of sensitivity and specificity
coords(roc.out, x="best")
library(ISLR2)
names(Smarket)
dim(Smarket)
summary(Smarket)
# summary prints the variables
pairs(Smarket)
cor(Smarket)
cor(Smarket)
round(cor(Smarket[,-9]), 3)
attach(Smarket)
plot(Volume, xlab="time")
glm.fits <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial)
summary(glm.fits)
# alternative syntax using the "dot"
glm.fits <- glm(Direction~.-Today-Year, data=Smarket, family=binomial)
summary(glm.fits)
# obtain fitted probabilities
glm.probs <- predict(glm.fits, type="response")
glm.probs[1:10]
# check the coding of Direction (to properly interpret probabilities)
contrasts(Direction)
glm.pred <- rep("Down",1250)
glm.pred[glm.probs>.5] <- "Up"
table(glm.pred,Direction)
# overall (training) error rate
(141+457)/1250
# 0.4784; or 47%
#   We know that random guessing (toss a coin to choose investments), error rate is 50%
#      This is slightly smaller than 50%, but this is a training error rate
#      This error rate is underestimated, true error is most likely large (probably 50%)
Direction
# proportions of "Up" and "Down"
table(Direction)/length(Direction)
library(pROC)
roc.out <- roc(Direction, glm.probs, levels=c("Down", "Up"))
plot(roc.out, print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
# reduced set of predictors
####################################
# Let's try tor educe number of predictiors: Lag1 and Lag2
glm.fits <- glm(Direction~Lag1+Lag2,data=Smarket,family=binomial)
glm.probs <- predict(glm.fits,type="response")
glm.pred <- rep("Down",1250)
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction)
# overall error rate
(102+488)/1250
table(Direction)/length(Direction)
train <- (Year<2005)
# creates a logical vector, T for data before 2005 and F for later
# Train on data from years less than 2005
Smarket.2005 <- Smarket[!train,]
# When we take S market and !train logical vector, we obtain the data for 2005
#   This is out validation set
dim(Smarket.2005)
# Could also
Direction.2005 <- Direction[!train]
# fit for same variables on Smarket on the subset train
#   Only works with the data where Train vector index is True
glm.fits <- glm(Direction~.-Today-Year, family=binomial, data=Smarket, subset=train)
# prediction on hold-out set
glm.probs <- predict(glm.fits,Smarket.2005,type="response")
glm.pred <- rep("Down",252)
glm.pred[glm.probs>.5] <- "Up"
table(glm.pred,Direction.2005)
(97+34)/252
table(Direction.2005)/length(Direction.2005)
x <- 1:4
x
x[2]
x[0]
x[0]
source("~/CMK/College/Padova/Spring 2023/Statistical Learning Mod B/Final Project/SL_Project/Project.r", echo=TRUE)
oversampled_train_data = ovun.sample(IsWinner ~., data = training_set[,-1], method = "over", p = 0.5, seed = 42)$data
sum(oversampled_train_data$IsWinner == 0)
sum(oversampled_train_data$IsWinner == 1)
logistic = glm(IsWinner ~ ., data = training_set[,c(-1,-2)], family = "binomial")
summary(logistic)
logistic_predictions_full = predict(logistic, newdata = test_set[,c(-1, -2)], type = "response")
logistic_predictions_full_02 = ifelse(logistic_predictions_full > 0.2, 1, 0)
logistic_accuracy_full_02 = sum(logistic_predictions_full_02 == test_set[2]) / dim(test_set[2])[1]
table(test_set$IsWinner, logistic_predictions_full_02)
false_positive_logistic_full_02 = table(test_set$IsWinner, logistic_predictions_full_02)[3]
negative_logistic_full_02 = table(test_set$IsWinner, logistic_predictions_full_02)[1] + table(test_set$IsWinner, logistic_predictions_full_02)[2]
typeIerror_logistic_full_02 = false_positive_logistic_full_02 / negative_logistic_full_02
true_positive_logistic_full_02 = table(test_set$IsWinner, logistic_predictions_full_02)[4]
positive_logistic_full_02 = table(test_set$IsWinner, logistic_predictions_full_02)[2] + table(test_set$IsWinner, logistic_predictions_full_02)[4]
sensitivity_logistic_full_02 = true_positive_logistic_full_02 / positive_logistic_full_02
logistic_predictions_full_03 = ifelse(logistic_predictions_full > 0.3, 1, 0)
logistic_accuracy_full_03 = sum(logistic_predictions_full_03 == test_set[2]) / dim(test_set[2])[1]
table(test_set$IsWinner, logistic_predictions_full_03)
false_positive_logistic_full_03 = table(test_set$IsWinner, logistic_predictions_full_03)[3]
negative_logistic_full_03 = table(test_set$IsWinner, logistic_predictions_full_03)[1] + table(test_set$IsWinner, logistic_predictions_full_03)[2]
typeIerror_logistic_full_03 = false_positive_logistic_full_03 / negative_logistic_full_03
true_positive_logistic_full_03 = table(test_set$IsWinner, logistic_predictions_full_03)[4]
positive_logistic_full_03 = table(test_set$IsWinner, logistic_predictions_full_03)[2] + table(test_set$IsWinner, logistic_predictions_full_03)[4]
sensitivity_logistic_full_03 = true_positive_logistic_full_03 / positive_logistic_full_03
logistic_predictions_full_04 = ifelse(logistic_predictions_full > 0.4, 1, 0)
logistic_accuracy_full_04 = sum(logistic_predictions_full_04 == test_set[2]) / dim(test_set[2])[1]
table(test_set$IsWinner, logistic_predictions_full_04)
false_positive_logistic_full_04 = table(test_set$IsWinner, logistic_predictions_full_04)[3]
negative_logistic_full_04 = table(test_set$IsWinner, logistic_predictions_full_04)[1] + table(test_set$IsWinner, logistic_predictions_full_04)[2]
typeIerror_logistic_full_04 = false_positive_logistic_full_04 / negative_logistic_full_04
true_positive_logistic_full_04 = table(test_set$IsWinner, logistic_predictions_full_04)[4]
positive_logistic_full_04 = table(test_set$IsWinner, logistic_predictions_full_04)[2] + table(test_set$IsWinner, logistic_predictions_full_04)[4]
sensitivity_logistic_full_04 = true_positive_logistic_full_04 / positive_logistic_full_04
roc.out <- roc(test_set$IsWinner, logistic_predictions_full)
plot(roc.out, print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
auc(roc.out)
oversampled_train_data
# Set the working directory to this file's folder
library("rstudioapi")
# Set the working directory to this file's folder
library("rstudioapi")
setwd(dirname(getActiveDocumentContext()$path))
load("final_df_n_str.RData")
Sys.setenv(LANG = "en")
library(pROC)
library(MASS)
library(ROSE)
library(confintr)
library(ggplot2)
library(correlation)
library(corrplot)
library(class)
library(caret)
library(glmnet)
data = final_df_n_str
data = data[,c("track_name", "artist_name", "IsWinner", "Year","year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
data$Year[data$Year == "Undefined"] <- data$year[data$Year == "Undefined"]
data = data[,c("track_name","artist_name", "IsWinner", "Year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
par(mfrow= c(2, 4))
hist(danceability, main='Danceability')
hist(duration_ms, main='Duration')
hist(energy, main='Energy')
hist(instrumentalness, main='Instrumentalness')
hist(loudness, main='Loudness')
hist(tempo, main='Tempo')
hist(valence, main='Valence')
par(mfrow= c(2, 4))
hist(acousticness, main='Acousticness')
hist(danceability, main='Danceability')
hist(duration_ms, main='Duration')
hist(energy, main='Energy')
hist(instrumentalness, main='Instrumentalness')
hist(loudness, main='Loudness')
hist(tempo, main='Tempo')
hist(valence, main='Valence')
View(dur_mode.aov)
### Data Preprocessing
# Set the working directory to this file's folder
library("rstudioapi")
setwd(dirname(getActiveDocumentContext()$path))
load("final_df_n_str.RData")
Sys.setenv(LANG = "en")
#install.packages("correlation")
#install.packages("confintr")
#install.packages("ROSE")
#install.packages("caret")
#install.packages("glmnet")
library(pROC)
library(MASS)
library(ROSE)
library(confintr)
library(ggplot2)
library(correlation)
library(corrplot)
library(class)
library(caret)
library(glmnet)
# Selecting the relevant variables
data = final_df_n_str
data = data[,c("track_name", "artist_name", "IsWinner", "Year","year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
# Merge the two year variable
data$Year[data$Year == "Undefined"] <- data$year[data$Year == "Undefined"]
data = data[,c("track_name","artist_name", "IsWinner", "Year", "followers", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "liveness", "loudness", "mode",
"tempo", "time_signature", "valence")]
# Eliminating duplicates
data$track_name == "Closing Time"
data$track_name == "Smells Like Teen Spirit"
data$track_name == "Don't Wanna Fight"
data[914, ]
data[789,]
data[669,]
data = data[-c(669, 789, 914),]
sum(data$Year < 1992)
nrow(data)
data = data[!data$Year < 1992,]
# Creating row names
names = paste0(data$track_name, " - ", data$artist_name)
# Eliminating unusable variables
data = data[,c("IsWinner", "Year", "acousticness", "danceability", "duration_ms",
"energy", "instrumentalness", "key", "loudness", "mode",
"tempo", "time_signature", "valence")]
data = cbind(names = names, data)
# Casting variables
data$IsWinner[data$IsWinner == "Winner"] = 1
data$IsWinner[data$IsWinner == "Nominee"] = 1
data$IsWinner[data$IsWinner == "Nothing"] = 0
data$IsWinner = as.integer(data$IsWinner)
data$Year = as.integer(data$Year)
data$mode = as.factor(data$mode)
data$key = as.factor(data$key)
data$time_signature = as.factor(data$time_signature)
summary(data)
# Checking balance between classes
length(data$IsWinner[data$IsWinner == 0]) / (length(data$IsWinner[data$IsWinner == 0]) + length(data$IsWinner[data$IsWinner == 1]))
length(data$IsWinner[data$IsWinner == 1]) / (length(data$IsWinner[data$IsWinner == 0]) + length(data$IsWinner[data$IsWinner == 1]))
# Splitting training and test set
training_size = floor(0.8 * nrow(data))
set.seed(42)
train_ind = sample(seq_len(nrow(data)), size = training_size)
training_set = data[train_ind,]
test_set = data[-train_ind,]
summary(training_set)
# Checking if the ratio is preserved
length(training_set$IsWinner[data$IsWinner == 0]) / (length(training_set$IsWinner[data$IsWinner == 0]) + length(training_set$IsWinner[data$IsWinner == 1]))
length(training_set$IsWinner[data$IsWinner == 1]) / (length(training_set$IsWinner[data$IsWinner == 0]) + length(training_set$IsWinner[data$IsWinner == 1]))
length(test_set$IsWinner[data$IsWinner == 0]) / (length(test_set$IsWinner[data$IsWinner == 0]) + length(test_set$IsWinner[data$IsWinner == 1]))
length(test_set$IsWinner[data$IsWinner == 1]) / (length(test_set$IsWinner[data$IsWinner == 0]) + length(test_set$IsWinner[data$IsWinner == 1]))
###############################################################################
# Exploratory Data Analysis
# Relationship between independent variables
attach(training_set)
# Correlations between continuous variables
cor_matrix = cor(training_set[,c(-1, -2, -9, -11, -13)])
# corrplot(cor_matrix, method='number')
# dev.new(width=10, height=5, unit="in")
png(file="corplot_indep_1.png",
width=1200, height=1000, pointsize = 26)
corrplot.mixed(cor_matrix, tl.pos='lt')
dev.off()
#pairs(training_set[,c(-1, -2, -9, -11, -13)], lower.panel = panel.smooth)
# Send pairs() to png to resize and visualize better
png(file = "corplot_indep_2.png", width = 1200, height = 1000, pointsize=20)
pairs(training_set[,c(-1, -2, -9, -11, -13)], lower.panel = panel.smooth)
dev.off()  # important!
# Association measure for categorical variables (Cramer's V is a normalized
# version of the chi-square statistics)
cramersv(matrix(c(as.numeric(key), as.numeric(mode)), ncol = 2))
cramersv(matrix(c(as.numeric(key), as.numeric(time_signature)), ncol = 2))
cramersv(matrix(c(as.numeric(mode), as.numeric(time_signature)), ncol = 2))
# Association between continuous and categorical variables
# Key
aco_key.aov <- aov(acousticness ~ key)
summary(aco_key.aov)
dan_key.aov <- aov(danceability ~ key)
summary(dan_key.aov) # SIGNIFICANT
dur_key.aov <- aov(duration_ms ~ key)
summary(dur_key.aov)
ene_key.aov <- aov(energy ~ key)
summary(ene_key.aov) # SIGNIFICANT
ins_key.aov <- aov(instrumentalness ~ key)
summary(ins_key.aov)
loud_key.aov <- aov(loudness ~ key)
summary(loud_key.aov)
tem_key.aov <- aov(tempo ~ key)
summary(tem_key.aov)
val_key.aov <- aov(valence ~ key)
summary(val_key.aov)
# Mode
aco_mode.aov <- aov(acousticness ~ mode)
summary(aco_mode.aov) # SIGNIFICANT
dan_mode.aov <- aov(danceability ~ mode)
summary(dan_mode.aov)
dur_mode.aov <- aov(duration_ms ~ mode)
summary(dur_mode.aov)
ene_mode.aov <- aov(energy ~ mode)
summary(ene_mode.aov) # SIGNIFICANT
ins_mode.aov <- aov(instrumentalness ~ mode)
summary(ins_mode.aov)
loud_mode.aov <- aov(loudness ~ mode)
summary(loud_mode.aov) # SIGNIFICANT
tem_mode.aov <- aov(tempo ~ mode)
summary(tem_mode.aov)
val_mode.aov <- aov(valence ~ mode)
summary(val_mode.aov)
# Time signature
aco_time.aov <- aov(acousticness ~ time_signature)
summary(aco_time.aov) # SIGNIFICANT
dan_time.aov <- aov(danceability ~ time_signature)
summary(dan_time.aov) # SIGNIFICANT
dur_time.aov <- aov(duration_ms ~ time_signature)
summary(dur_time.aov) # SIGNIFICANT
ene_time.aov <- aov(energy ~ time_signature)
summary(ene_time.aov) # SIGNIFICANT
ins_time.aov <- aov(instrumentalness ~ time_signature)
summary(ins_time.aov) # SIGNIFICANT
loud_time.aov <- aov(loudness ~ time_signature)
summary(loud_time.aov) # SIGNIFICANT
tem_time.aov <- aov(tempo ~ time_signature)
summary(tem_time.aov) # SIGNIFICANT
val_time.aov <- aov(valence ~ time_signature)
summary(val_time.aov) # SIGNIFICANT
# Partial correlations
correlation(training_set[,c(-1, -2, -9, -11, -13)], partial = TRUE)
# Plots of variables with the largest partial correlation
ggplot(data = training_set, aes(danceability, valence)) + geom_jitter(color = "blue")
ggplot(data = training_set, aes(loudness, energy)) + geom_jitter(color = "blue")
ggplot(data = training_set, aes(acousticness, energy)) + geom_jitter(color = "blue")
#Weird song veeeeeeeeeeeeeeeeeeeeeeeery long
which.max(data$duration_ms)
data[504, ]
##############
# Checking distributions
par(mfrow= c(2, 4))
# Continuous variables
hist(acousticness, main='Acousticness')
hist(danceability, main='Danceability')
hist(duration_ms, main='Duration')
hist(energy, main='Energy')
hist(instrumentalness, main='Instrumentalness')
hist(loudness, main='Loudness')
hist(tempo, main='Tempo')
hist(valence, main='Valence')
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 120,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 30,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
par(mfrow = c(1, 3))
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 125,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
hist(x)
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 130,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 135,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 140,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 130,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 132,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 131,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 130,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 128,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
hist(x)
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 126,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 125,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$valence
hist(x)
abline(v = mean(x),                       # Add line for mean
col = "red",
lwd = 3)
text(x = mean(x) * 0.5,                   # Add text for mean
y = 120,
paste("Mean =", round(mean(x), digits=2)),
col = "red",
cex = 1)
x <- data[data$IsWinner == 1,]$valence
par(mfrow = c(1, 3))
barplot(table(key), main = "Key distribution")
barplot(table(mode), main = "Mode")
barplot(table(time_signature), main = "Time signature")
par(mfrow = c(1, 2))
x <- data[data$IsWinner == 0,]$key
barplot(table(x), main = "Key: Non-Nominated")
x <- data[data$IsWinner == 1,]$key
barplot(table(x), main = "Key: Nominated/Winner")
